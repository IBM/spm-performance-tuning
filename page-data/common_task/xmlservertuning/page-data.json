{"componentChunkName":"component---src-pages-common-task-xmlservertuning-mdx","path":"/common_task/xmlservertuning/","result":{"pageContext":{"frontmatter":{"title":"Tuning the XML server","description":"Tuning the XML server"},"relativePagePath":"/common_task/xmlservertuning.mdx","titleType":"page","MdxNode":{"id":"404afa9b-4330-53ff-a18d-6f07815627a6","children":[],"parent":"7e94d646-af28-5fb0-a4c1-c4712d70e60d","internal":{"content":"---\ntitle: Tuning the XML server\ndescription: Tuning the XML server\n---\n\n## Contents\n\n<AnchorLinks small>\n  <AnchorLink>Introduction</AnchorLink>\n  <AnchorLink>Becoming aware of how your XML server normally performs</AnchorLink>\n  <AnchorLink>Identifying causes of poor performance</AnchorLink>\n  <AnchorLink>Tuning and configuration changes</AnchorLink>\n</AnchorLinks>\n\n## Introduction\n\nThese are the basic high-level steps for tuning the XML server:\n\n1. Be aware of, and familiar with, how your XML server performs under normal circumstances.\n   Thus, you should be able to know what good versus poor performance looks like.  To do this takes time. To obtain this performance awareness you need to review the available data on a regular basis.\n2. When you identify poor performance you need to know where to look to identify the reason or cause.\n3. Depending on the symptoms, etc. apply configuration or tuning changes, as appropriate.\n\n## Becoming aware of how your XML server normally performs\n\nYour main source of XML server performance information comes from its `stats/ThreadWorkerPool-*` files. For more information see these XML server topics in the product documentation:\n\n* **Statistics** in the *Social Program Management XML Infrastructure Guide* - outlines the information available in these files.\n* **Configuring the XML server** in the **XML Infrastructure Guide** - identifies the configuration necessary to produce these files.\n\n## Identifying causes of poor performance\n\nIf the the `stats/ThreadWorkerPool-*` files indicate a performance problem--for example: showing increasing processing times--these are some things to check:\n\n* Check the `$CURAMSDEJ/xmlserver/tmp/xmlserver.log` file for unexpected errors:\n  * Look for any indications of socket timeouts or dropped connections, which could be indicators that the `<THREAD_POOL_QUEUE_SIZE>` setting is too small.\n    As per the **XML Infrastructure Guide**, that setting determines the point at which requests are held inside the XML server rather than in the TCP backlog queue.\n    How the TCP backlog queue behaves when it is exhausted depends on the underlying operating system and in some cases may retry or timeout the connection.\n    Some indicators of socket connection issues in `xmlserver.log` might include:\n    * `WRN_CONN_SET_SO_TIMEOUT` exceptions indicating socket reads are hitting the socket read timeout (XML server `<SO_TIMEOUT>` setting), which defaults to 60 seconds (60000 ms).\n      However, there could be reasons for socket timeouts other than the TCP backlog queue being exhausted, for instance poor performance in the application server interacting with the XML server.\n    * `ITDXS521-IO ERROR` messages occur when the XML server catches `java.io.IOException` exceptions and these could occur due to the `<THREAD_POOL_QUEUE_SIZE>` setting, described above.\n  * Check the performance of the application server(s) communicating with this XML server to confirm it is performing adequately and not impacting the XML server.\n  * Run Java garbage collection (GC) tracing to confirm and evaluate the performance of the Java Heap used by the XML server.\n    Use the `java.jvmargs` Ant property to pass GC settings to the JVM when starting the XML server.  For example, using an IBM JVM: `ant -f xmlserver.xml -Djava.jvmargs=\"-verbose:gc -Xverbosegclog:/tmp/gc/verbosegc.log\"`\n  * Confirm the overall system performance; for instance, CPU and memory utilization. There are a number of tools available for monitoring, depending on the context of the platform.\n\n## Tuning and configuration changes\n\nThese are the areas available within, or closely related to, the XML server for tuning:\n\n* These XML server settings in `xmlserverconfigconfig.xml`, which are described in the related **XML Infrastructure Guide**, are specific to the XML server:\n  * `<THREAD_POOL_QUEUE_SIZE>`\n  * `<THREAD_POOL_SIZE>`\n  * `<USE_TEMPLATE_CACHE>`\n  * `<SO_TIMEOUT>`\n* These Java JVM settings:\n  * Thread stack size can be set when starting the XML server. For example: `ant -f xmlserver.xml -Djava.thread.stack.size=\"-Xss8m\"`.\n    For more information see **Overriding the Java thread stack size** in the **XML Infrastructure Guide**.\n    If you change the default number of XML server threads (`<THREAD_POOL_SIZE>`) this setting may also need to be adjusted.\n  * Java heap is set in `xmlserver.xml` as an Ant property, `java.maxmemory`, specifying the `maxmemory` attribute of the Ant `<java>` task.\n    For example: `ant -f xmlserver.xml -Djava.maxmemory=\"1024m\"`.\n* For on premise deployments the XML server provides load balancing functionality, which is described in **Load balancing and failover** in the **XML Infrastructure Guide**.\n  However, when deployed to Kubernetes the native scaling capabilities of that platform should be used instead.\n","type":"Mdx","contentDigest":"322982bdf23442a91fb0589384b87a87","owner":"gatsby-plugin-mdx","counter":116},"frontmatter":{"title":"Tuning the XML server","description":"Tuning the XML server"},"exports":{},"rawBody":"---\ntitle: Tuning the XML server\ndescription: Tuning the XML server\n---\n\n## Contents\n\n<AnchorLinks small>\n  <AnchorLink>Introduction</AnchorLink>\n  <AnchorLink>Becoming aware of how your XML server normally performs</AnchorLink>\n  <AnchorLink>Identifying causes of poor performance</AnchorLink>\n  <AnchorLink>Tuning and configuration changes</AnchorLink>\n</AnchorLinks>\n\n## Introduction\n\nThese are the basic high-level steps for tuning the XML server:\n\n1. Be aware of, and familiar with, how your XML server performs under normal circumstances.\n   Thus, you should be able to know what good versus poor performance looks like.  To do this takes time. To obtain this performance awareness you need to review the available data on a regular basis.\n2. When you identify poor performance you need to know where to look to identify the reason or cause.\n3. Depending on the symptoms, etc. apply configuration or tuning changes, as appropriate.\n\n## Becoming aware of how your XML server normally performs\n\nYour main source of XML server performance information comes from its `stats/ThreadWorkerPool-*` files. For more information see these XML server topics in the product documentation:\n\n* **Statistics** in the *Social Program Management XML Infrastructure Guide* - outlines the information available in these files.\n* **Configuring the XML server** in the **XML Infrastructure Guide** - identifies the configuration necessary to produce these files.\n\n## Identifying causes of poor performance\n\nIf the the `stats/ThreadWorkerPool-*` files indicate a performance problem--for example: showing increasing processing times--these are some things to check:\n\n* Check the `$CURAMSDEJ/xmlserver/tmp/xmlserver.log` file for unexpected errors:\n  * Look for any indications of socket timeouts or dropped connections, which could be indicators that the `<THREAD_POOL_QUEUE_SIZE>` setting is too small.\n    As per the **XML Infrastructure Guide**, that setting determines the point at which requests are held inside the XML server rather than in the TCP backlog queue.\n    How the TCP backlog queue behaves when it is exhausted depends on the underlying operating system and in some cases may retry or timeout the connection.\n    Some indicators of socket connection issues in `xmlserver.log` might include:\n    * `WRN_CONN_SET_SO_TIMEOUT` exceptions indicating socket reads are hitting the socket read timeout (XML server `<SO_TIMEOUT>` setting), which defaults to 60 seconds (60000 ms).\n      However, there could be reasons for socket timeouts other than the TCP backlog queue being exhausted, for instance poor performance in the application server interacting with the XML server.\n    * `ITDXS521-IO ERROR` messages occur when the XML server catches `java.io.IOException` exceptions and these could occur due to the `<THREAD_POOL_QUEUE_SIZE>` setting, described above.\n  * Check the performance of the application server(s) communicating with this XML server to confirm it is performing adequately and not impacting the XML server.\n  * Run Java garbage collection (GC) tracing to confirm and evaluate the performance of the Java Heap used by the XML server.\n    Use the `java.jvmargs` Ant property to pass GC settings to the JVM when starting the XML server.  For example, using an IBM JVM: `ant -f xmlserver.xml -Djava.jvmargs=\"-verbose:gc -Xverbosegclog:/tmp/gc/verbosegc.log\"`\n  * Confirm the overall system performance; for instance, CPU and memory utilization. There are a number of tools available for monitoring, depending on the context of the platform.\n\n## Tuning and configuration changes\n\nThese are the areas available within, or closely related to, the XML server for tuning:\n\n* These XML server settings in `xmlserverconfigconfig.xml`, which are described in the related **XML Infrastructure Guide**, are specific to the XML server:\n  * `<THREAD_POOL_QUEUE_SIZE>`\n  * `<THREAD_POOL_SIZE>`\n  * `<USE_TEMPLATE_CACHE>`\n  * `<SO_TIMEOUT>`\n* These Java JVM settings:\n  * Thread stack size can be set when starting the XML server. For example: `ant -f xmlserver.xml -Djava.thread.stack.size=\"-Xss8m\"`.\n    For more information see **Overriding the Java thread stack size** in the **XML Infrastructure Guide**.\n    If you change the default number of XML server threads (`<THREAD_POOL_SIZE>`) this setting may also need to be adjusted.\n  * Java heap is set in `xmlserver.xml` as an Ant property, `java.maxmemory`, specifying the `maxmemory` attribute of the Ant `<java>` task.\n    For example: `ant -f xmlserver.xml -Djava.maxmemory=\"1024m\"`.\n* For on premise deployments the XML server provides load balancing functionality, which is described in **Load balancing and failover** in the **XML Infrastructure Guide**.\n  However, when deployed to Kubernetes the native scaling capabilities of that platform should be used instead.\n","fileAbsolutePath":"/home/runner/work/curam-performance-tuning/curam-performance-tuning/src/pages/common_task/xmlservertuning.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","56986546","768070550"]}